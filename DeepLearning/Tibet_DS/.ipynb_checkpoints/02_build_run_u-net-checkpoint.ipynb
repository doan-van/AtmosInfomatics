{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68df7b09",
   "metadata": {},
   "source": [
    "# This is code to downscale rough-resolution temperature to high-resolution one\n",
    "\n",
    "## This is test for Himalaya and Tibet region (to see how AI handle stiff terrain is intersting case study)\n",
    "\n",
    "![image.png](attachment:55faf5fb-a759-418a-b58e-0a40ef17bf57.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8958799",
   "metadata": {},
   "source": [
    "## first let import libaries\n",
    "\n",
    "If there is necessity to install any libraries, do it.\n",
    "\n",
    "For example\n",
    "\n",
    "conda install scipy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf77cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "#import ecubevis as ecv\n",
    "#import climetlab as cml\n",
    "import tensorflow as tf \n",
    "# all the layers used for U-net\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,\n",
    "                                     Conv2DTranspose, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.utils as ku\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import sys\n",
    "#from unet_functions import lr_scheduler #, encoder_block, decoder_block, conv_block\n",
    "print('===')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6190c884",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Prepare input data for Unet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e6d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain0 = xr.open_dataset('data/tb_train.nc')\n",
    "dval0 = xr.open_dataset('data/tb_val.nc')\n",
    "dtest0 = xr.open_dataset('data/tb_test.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d392f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datnorm(d): \n",
    "    return (d - d.mean()) / d.std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c1513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "dtrain, dval, dtest = datnorm(dtrain0), datnorm(dval0), datnorm(dtest0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d40c509",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_data = dtrain['lo'].values\n",
    "X_train = np.expand_dims(int_data,3)\n",
    "y_train = dtrain['hi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c141ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.expand_dims(dval['lo'].values,3)\n",
    "y_val = dval['hi'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9c7aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "X_test = np.expand_dims(dtest['lo'].values,3)\n",
    "y_test = dtest['hi'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229eb9a",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409224e",
   "metadata": {},
   "source": [
    "## After long coding above, finally, what we want is three kinds of data\n",
    "\n",
    "> Training data\n",
    "\n",
    "> Validation data\n",
    "\n",
    "> Testing data\n",
    "\n",
    "In each kind of data: there should be two dataset\n",
    "\n",
    "X (predictors) having four dimensions (n_sample, y_axis, x_axis, n_variables)\n",
    "\n",
    "Y (preditant) having three or four dimensions (n_sample, y_axis, x_axis, n_variables (optional) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6bd679",
   "metadata": {
    "lines_to_end_of_cell_marker": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Shape of X_train: ', X_train.shape)\n",
    "print('Shape of y_train: ', y_train.shape)\n",
    "print('Shape of X_validation: ', X_val.shape)\n",
    "print('Shape of y_validation: ', y_val.shape)\n",
    "print('Shape of X_test: ', X_test.shape)\n",
    "print('Shape of y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffef998",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Define encoder and decorder functions\n",
    "\n",
    "\n",
    "![image.png](attachment:e1f58715-31b0-4293-ab50-dfe6349bb052.png)\n",
    "\n",
    "\n",
    "https://www.geeksforgeeks.org/u-net-architecture-explained/\n",
    "\n",
    "With decoder UNet become different with normal CNN\n",
    "\n",
    "\n",
    "+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e284c5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters: int, kernel: tuple = (3,3), padding: str = \"same\",\n",
    "               activation: str = \"relu\", kernel_init: str = \"he_normal\", l_batch_normalization: bool = True):\n",
    "    \"\"\"\n",
    "    A convolutional layer with optional batch normalization\n",
    "    :param inputs: the input data with dimensions nx, ny and nc\n",
    "    :param num_filters: number of filters (output channel dimension)\n",
    "    :param kernel: tuple indictating kernel size\n",
    "    :param padding: technique for padding (e.g. \"same\" or \"valid\")\n",
    "    :param activation: activation fuction for neurons (e.g. \"relu\")\n",
    "    :param kernel_init: initialization technique (e.g. \"he_normal\" or \"glorot_uniform\")\n",
    "    \"\"\"\n",
    "    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)\n",
    "    if l_batch_normalization: x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca4c2d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding=\"same\", activation=\"relu\", \n",
    "                     kernel_init=\"he_normal\", l_batch_normalization=True):\n",
    "    \"\"\"\n",
    "    Sequential application of two convolutional layers (using conv_block).\n",
    "    \"\"\"\n",
    "    \n",
    "    x = conv_block(inputs, num_filters, kernel, padding, activation,kernel_init, l_batch_normalization)\n",
    "    for i in np.arange(n-1):\n",
    "        x = conv_block(x, num_filters, kernel, padding, activation,kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead879f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters, kernel_maxpool: tuple=(2,2), l_large: bool=True):\n",
    "    \"\"\"\n",
    "    One complete encoder-block used in U-net\n",
    "    \"\"\"\n",
    "    if l_large: x = conv_block_n(inputs, num_filters, n=2)\n",
    "    else: x = conv_block(inputs, num_filters) \n",
    "    p = MaxPool2D(kernel_maxpool)(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca33d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= \"same\", \n",
    "                  activation=\"relu\", kernel_init=\"he_normal\", l_batch_normalization: bool=True):\n",
    "    \"\"\"\n",
    "    One complete decoder block used in U-net (reverting the encoder)\n",
    "    \"\"\"\n",
    "    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dd724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e18d2e5b",
   "metadata": {},
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589deb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a earning-rate scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "  if epoch < 5:\n",
    "    return lr\n",
    "  elif epoch >= 5 and epoch < 30:\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "  elif epoch >= 30:\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c929784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a246a773",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "plt.plot([ lr_scheduler(e,5*10**(-4) ) for e in range(150)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8135b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 150\n",
    "shape_in = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29642d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running unet using unet_functions\n",
    "rununet = 0\n",
    "if rununet:\n",
    "\n",
    "    # parameters \n",
    "        \n",
    "    callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "    \n",
    "    # build model    \n",
    "    inputs = Input(shape_in)\n",
    "    \n",
    "    \"\"\" encoder \"\"\"\n",
    "    channels_start=56\n",
    "    #channels_start=16\n",
    "    \n",
    "    s1, e1 = encoder_block(inputs, channels_start, l_large=True)\n",
    "    s2, e2 = encoder_block(e1, channels_start*2, l_large=False)\n",
    "    s3, e3 = encoder_block(e2, channels_start*4, l_large=False)\n",
    "    \n",
    "    \"\"\" bridge encoder <-> decoder \"\"\"\n",
    "    b1 = conv_block(e3, channels_start*8)\n",
    "    \n",
    "    \"\"\" decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, channels_start*4)\n",
    "    d2 = decoder_block(d1, s2, channels_start*2)\n",
    "    d3 = decoder_block(d2, s1, channels_start)\n",
    "    \n",
    "    output_temp = Conv2D(1, (1,1), kernel_initializer=\"he_normal\", name=\"output_temp\")(d3)\n",
    "    \n",
    "    unet_model= Model(inputs, output_temp, name=\"t2m_downscaling_unet\")\n",
    "    \n",
    "    #ku.plot_model(unet_model, show_shapes=True)\n",
    "    \n",
    "    unet_model.compile(optimizer=Adam(learning_rate=5*10**(-4)), loss=\"mae\")\n",
    "    \n",
    "    if 1:\n",
    "        history = unet_model.fit(x=X_train, \n",
    "                                 y=y_train, \n",
    "                                 batch_size=batch_size,\n",
    "                                 epochs=epochs, \n",
    "                                 callbacks=[callback],\n",
    "                                 validation_data=(X_val, y_val ),\n",
    "                                 verbose = 1 # dont show ====== if want to show =1\n",
    "                                 )\n",
    "        # save model to ecmwf\n",
    "        unet_model.save('tb_small')\n",
    "        print('Finished run')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4c5dd",
   "metadata": {},
   "source": [
    "## Predict and verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2547c5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e4f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756afc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python tf",
   "language": "python",
   "name": "tf"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
