from tensorflow import keras


import tensorflow as tf


tf.__version__


keras.__version__


import numpy as np
import xarray as xr
import tensorflow as tf 
# all the layers used for U-net
from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,
                                     Conv2DTranspose, Input, MaxPool2D)
from keras.models import Model
import keras.utils as ku
from keras.optimizers import Adam
import sys


dtrain0 = xr.open_dataset('data/nagoya_train.nc')
dval0 = xr.open_dataset('data/nagoya_val.nc')
dtest0 = xr.open_dataset('data/nagoya_test.nc')


# normalize data 
def datnorm(d): 
    return (d - d.mean()) / d.std() 


# normalize data
dtrain, dval, dtest = datnorm(dtrain0), datnorm(dval0), datnorm(dtest0)
#dtrain, dval, dtest = dtrain0, dval0, dtest0


int_data = dtrain['lo'].values
X_train = np.expand_dims(int_data,3)
y_train = dtrain['hi'].values


X_val = np.expand_dims(dval['lo'].values,3)
y_val = dval['hi'].values


X_test = np.expand_dims(dtest['lo'].values,3)
y_test = dtest['hi'].values



print('Shape of X_train: ', X_train.shape)
print('Shape of y_train: ', y_train.shape)
print('Shape of X_validation: ', X_val.shape)
print('Shape of y_validation: ', y_val.shape)
print('Shape of X_test: ', X_test.shape)
print('Shape of y_test: ', y_test.shape)





from keras.callbacks import LearningRateScheduler

def scheduler(epoch, lr):
    if epoch < 50:
        return lr
    else:
        return lr * 0.95  # Reduce learning rate by 5% after each epoch from 50 onward

lr_callback = LearningRateScheduler(scheduler)



from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout
from keras.models import Model
from keras.optimizers import Adam
from keras.losses import MeanSquaredError
from keras.callbacks import EarlyStopping, LearningRateScheduler
import matplotlib.pyplot as plt

# Define the tiny U-Net model adapted for input_shape=(120, 104, 1)
def tiny_unet(input_shape=(120, 104, 1)):
    inputs = Input(shape=input_shape)
    
    # Downsampling layer 1
    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)
    conv1 = Dropout(0.1)(conv1)
    pool1 = MaxPooling2D((2, 2))(conv1)
    
    # Downsampling layer 2
    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)
    conv2 = Dropout(0.1)(conv2)
    pool2 = MaxPooling2D((2, 2))(conv2)
    
    # Bottleneck
    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)
    
    # Upsampling layer 1
    up2 = UpSampling2D((2, 2))(conv3)
    concat2 = Concatenate()([up2, conv2])
    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)
    conv4 = Dropout(0.1)(conv4)
    
    # Upsampling layer 2
    up1 = UpSampling2D((2, 2))(conv4)
    concat1 = Concatenate()([up1, conv1])
    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(concat1)
    conv5 = Dropout(0.1)(conv5)
    
    # Output layer for continuous values (linear activation)
    outputs = Conv2D(1, (1, 1), activation=None)(conv5)
    
    return Model(inputs, outputs)

# Instantiate the tiny U-Net model with the new input shape
unet_model = tiny_unet(input_shape=(120, 104, 1))

# Compile the model with MSE loss and Adam optimizer
unet_model.compile(optimizer=Adam(learning_rate=0.00005), 
                   loss=MeanSquaredError(), 
                   metrics=['mae'])

# Define a learning rate schedule (exponential decay)
def lr_schedule(epoch, lr):
    decay_rate = 0.95  # Decay factor
    decay_epoch = 10   # Apply decay every 10 epochs
    if epoch % decay_epoch == 0 and epoch != 0:
        return lr * decay_rate
    return lr

# Define callbacks
early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)

# Train the model with the learning rate scheduler
history = unet_model.fit(
    x=X_train, 
    y=y_train, 
    validation_data=(X_val, y_val),
    epochs=300,
    batch_size=16,
    callbacks=[early_stop, lr_scheduler]
)

# Save the model
unet_model.save('nagoya_tiny_unet_120x104.keras')

# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()
plt.grid(True)
plt.show()




unet_model.summary()


from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Dropout, BatchNormalization
from keras.models import Model
from keras.optimizers import Adam
from keras.losses import Huber
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
import matplotlib.pyplot as plt

# Define an enhanced U-Net model with increased capacity, batch normalization, and dropout
def enhanced_unet(input_shape=(120, 104, 1)):
    inputs = Input(shape=input_shape)
    
    # Downsampling layer 1
    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(inputs)
    conv1 = BatchNormalization()(conv1)
    conv1 = Dropout(0.2)(conv1)
    pool1 = MaxPooling2D((2, 2))(conv1)
    
    # Downsampling layer 2
    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(pool1)
    conv2 = BatchNormalization()(conv2)
    conv2 = Dropout(0.2)(conv2)
    pool2 = MaxPooling2D((2, 2))(conv2)
    
    # Additional downsampling layer 3
    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(pool2)
    conv3 = BatchNormalization()(conv3)
    conv3 = Dropout(0.2)(conv3)
    pool3 = MaxPooling2D((2, 2))(conv3)
    
    # Bottleneck
    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(pool3)
    conv4 = BatchNormalization()(conv4)
    
    # Upsampling layer 1
    up3 = UpSampling2D((2, 2))(conv4)
    concat3 = Concatenate()([up3, conv3])
    conv5 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(concat3)
    conv5 = BatchNormalization()(conv5)
    conv5 = Dropout(0.2)(conv5)
    
    # Upsampling layer 2
    up2 = UpSampling2D((2, 2))(conv5)
    concat2 = Concatenate()([up2, conv2])
    conv6 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(concat2)
    conv6 = BatchNormalization()(conv6)
    conv6 = Dropout(0.2)(conv6)
    
    # Upsampling layer 3
    up1 = UpSampling2D((2, 2))(conv6)
    concat1 = Concatenate()([up1, conv1])
    conv7 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer='l2')(concat1)
    conv7 = BatchNormalization()(conv7)
    conv7 = Dropout(0.2)(conv7)
    
    # Output layer for continuous values (linear activation)
    outputs = Conv2D(1, (1, 1), activation=None)(conv7)
    
    return Model(inputs, outputs)

# Instantiate the model with the updated input shape
unet_model = enhanced_unet(input_shape=(120, 104, 1))

# Compile the model with Huber loss and a lower learning rate
unet_model.compile(optimizer=Adam(learning_rate=1e-5), 
                   loss=Huber(delta=1.0), 
                   metrics=['mae'])

# Define callbacks: early stopping and adaptive learning rate scheduler
early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6, verbose=1)

# Train the model
history = unet_model.fit(
    x=X_train, 
    y=y_train, 
    validation_data=(X_val, y_val),
    epochs=300,
    batch_size=16,
    callbacks=[early_stop, reduce_lr]
)

# Save the model
unet_model.save('enhanced_unet_120x104.keras')

# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()
plt.grid(True)
plt.show()



import os
# load model and run
xmodel = tf.keras.models.load_model('nagoya_tiny_unet_120x104.keras') 

#print(xmodel.summary())

y_pred_val = xmodel.predict(X_val, verbose=1)
y_pred_test = xmodel.predict(X_test, verbose=1) 

# return values to Kelvin 
x1, x2 = dtest0.mean()['hi'], dtest0.std()['hi']
y_pred_test_r = y_pred_test*x2.values + x1.values

x1, x2 = dval0.mean()['hi'], dval0.std()['hi']
y_pred_val_r = y_pred_val*x2.values + x1.values


do = xr.Dataset( )
do['pred'] = ( ('dat', 'latitude', 'longitude'), y_pred_test_r.squeeze())  
do.coords['latitude'] = dtest0.latitude
do.coords['longitude'] = dtest0.longitude
do['real'] = dtest0['hi']

dv = xr.Dataset( )
dv['pred'] = ( ('dat', 'latitude', 'longitude'), y_pred_val_r.squeeze())  
dv.coords['latitude'] = dval0.latitude
dv.coords['longitude'] = dval0.longitude
dv['real'] = dval0['hi']

odir = 'output/'
if not os.path.exists(odir): os.makedirs(odir)
do.to_netcdf(odir+'prediction.nc')
dv.to_netcdf(odir+'validation.nc')
do.close()
dv.close()

#do.pred[0].plot()
#plt.show()
#dtest0['hi'][0].plot()
#plt.show()
#bias = do.pred - dtest0.hi.values
#bias[0].plot()
#print(bias.mean())   

print(do)
print(dv)

do['real'][1].plot()
plt.show()
do['pred'][1].plot()



