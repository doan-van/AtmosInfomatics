from tensorflow import keras
import tensorflow as tf
import numpy as np
import xarray as xr
import tensorflow as tf 
# all the layers used for U-net
from keras.layers import (Activation, BatchNormalization, Concatenate, Conv2D,
                                     Conv2DTranspose, Input, MaxPool2D)
from keras.models import Model
import keras.utils as ku
from keras.optimizers import Adam
import sys



dtrain0 = xr.open_dataset('data/test1_train.nc')
dval0 = xr.open_dataset('data/test1_val.nc')
dtest0 = xr.open_dataset('data/test1_test.nc')

# %%
# normalize data 
def datnorm(d): 
    return (d - d.mean()) / d.std() 

# %%
# normalize data
dtrain, dval, dtest = datnorm(dtrain0), datnorm(dval0), datnorm(dtest0)

# %%
int_data = dtrain['lo'].values
X_train = np.expand_dims(int_data,3)
y_train = dtrain['hi'].values

# %%
X_val = np.expand_dims(dval['lo'].values,3)
y_val = dval['hi'].values

# %%
X_test = np.expand_dims(dtest['lo'].values,3)
y_test = dtest['hi'].values


# %%

print('Shape of X_train: ', X_train.shape)
print('Shape of y_train: ', y_train.shape)
print('Shape of X_validation: ', X_val.shape)
print('Shape of y_validation: ', y_val.shape)
print('Shape of X_test: ', X_test.shape)
print('Shape of y_test: ', y_test.shape)



def conv_block(inputs, num_filters: int, kernel: tuple = (3,3), padding: str = "same",
               activation: str = "relu", kernel_init: str = "he_normal", l_batch_normalization: bool = True):

    x = Conv2D(num_filters, kernel, padding=padding, kernel_initializer=kernel_init)(inputs)
    if l_batch_normalization: x = BatchNormalization()(x)
    x = Activation(activation)(x)
    return x


# %%
def conv_block_n(inputs, num_filters, n=2, kernel=(3,3), padding="same", activation="relu", 
                     kernel_init="he_normal", l_batch_normalization=True):
    
    x = conv_block(inputs, num_filters, kernel, padding, activation,kernel_init, l_batch_normalization)
    for i in np.arange(n-1):
        x = conv_block(x, num_filters, kernel, padding, activation,kernel_init, l_batch_normalization)
    
    return x

# %%
def encoder_block(inputs, num_filters, kernel_maxpool: tuple=(2,2), l_large: bool=True):

    if l_large: x = conv_block_n(inputs, num_filters, n=2)
    else: x = conv_block(inputs, num_filters) 
    p = MaxPool2D(kernel_maxpool)(x)
    return x, p

# %%
def decoder_block(inputs, skip_features, num_filters, kernel: tuple=(3,3), strides_up: int=2, padding: str= "same", 
                  activation="relu", kernel_init="he_normal", l_batch_normalization: bool=True):

    x = Conv2DTranspose(num_filters, (strides_up, strides_up), strides=strides_up, padding="same")(inputs)
    x = Concatenate()([x, skip_features])
    x = conv_block_n(x, num_filters, 2, kernel, padding, activation, kernel_init, l_batch_normalization)
    
    return x


# %% [markdown]
# ### Define learning rate (need to learn more)

# %%
# define a earning-rate scheduler
def lr_scheduler(epoch, lr):
  if epoch < 5:
    return float(lr)
  elif epoch >= 5:
    return float(lr * tf.math.exp(-0.1))
  #elif epoch >= 30:
  #  return float(lr)

# %%
#plt.plot([ lr_scheduler(e,5*10**(-4) ) for e in range(150)])

# %% [markdown]
# ## BUILDING U-NET HERE


# %%
batch_size = 32
epochs = 150
channels_start=56 
shape_in = X_train.shape[1:]

# %%
# parameters 
callback = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)

# build model    
inputs = Input(shape_in)

""" encoder """
s1, e1 = encoder_block(inputs, channels_start, l_large=True)
s2, e2 = encoder_block(e1, channels_start*2, l_large=False)
s3, e3 = encoder_block(e2, channels_start*4, l_large=False)

""" bridge encoder <-> decoder """
b1 = conv_block(e3, channels_start*8)

""" decoder """
d1 = decoder_block(b1, s3, channels_start*4)
d2 = decoder_block(d1, s2, channels_start*2)
d3 = decoder_block(d2, s1, channels_start)

output_temp = Conv2D(1, (1,1), kernel_initializer="he_normal", name="output_temp")(d3)

unet_model= Model(inputs, output_temp, name="t2m_downscaling_unet")

#ku.plot_model(unet_model, show_shapes=True)

unet_model.compile(optimizer=Adam(learning_rate=5*10**(-4)), loss="mse")

# %% [markdown]
# ## RUN U-NET HERE
#
# It will take a while to train model

# %%

if 1: 
    history = unet_model.fit(x=X_train, 
                             y=y_train, 
                             batch_size=batch_size,
                             epochs=epochs, 
                             callbacks=[callback],
                             validation_data=(X_val, y_val ),
                             verbose = 1 # dont show ====== if want to show =1
                             )
    # save model to ecmwf
    unet_model.save('test_small.keras')
    
    print('Finished run')

# %% [markdown]
# ## Predict and verification

# %%
unet_model.summary()


import matplotlib.pyplot as plt
# Plot training and validation loss
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curves')
plt.legend()
plt.grid(True)
plt.show()



import os
# load model and run
xmodel =  unet_model #tf.keras.models.load_model('nagoya_tiny_unet_120x104.keras') 

#print(xmodel.summary())

y_pred_val = xmodel.predict(X_val, verbose=1)
y_pred_test = xmodel.predict(X_test, verbose=1) 

# return values to Kelvin 
x1, x2 = dtest0.mean()['hi'], dtest0.std()['hi']
y_pred_test_r = y_pred_test*x2.values + x1.values

x1, x2 = dval0.mean()['hi'], dval0.std()['hi']
y_pred_val_r = y_pred_val*x2.values + x1.values


do = xr.Dataset( )
do['pred'] = ( ('dat', 'latitude', 'longitude'), y_pred_test_r.squeeze())  
do.coords['latitude'] = dtest0.latitude
do.coords['longitude'] = dtest0.longitude
do['real'] = dtest0['hi']

dv = xr.Dataset( )
dv['pred'] = ( ('dat', 'latitude', 'longitude'), y_pred_val_r.squeeze())  
dv.coords['latitude'] = dval0.latitude
dv.coords['longitude'] = dval0.longitude
dv['real'] = dval0['hi']

odir = 'output/'
if not os.path.exists(odir): os.makedirs(odir)
do.to_netcdf(odir+'prediction.nc')
dv.to_netcdf(odir+'validation.nc')
do.close()
dv.close()

#do.pred[0].plot()
#plt.show()
#dtest0['hi'][0].plot()
#plt.show()
#bias = do.pred - dtest0.hi.values
#bias[0].plot()
#print(bias.mean())   

print(do)
print(dv)

do['real'][1].plot()
plt.show()
do['pred'][1].plot()


import cartopy
import cartopy.crs as ccrs
import matplotlib as mpl
import matplotlib.pyplot as plt
import os, glob, sys
lat, lon = do.latitude.values, do.longitude.values
ntime = 0
zz = [ dtest0['lo'][ntime] , do['pred'][ntime] - do['real'][ntime], 
      do['pred'][ntime], do['real'][ntime] ] 

lat2d, lon2d = np.meshgrid(lon, lat)


fig = plt.figure(figsize=(8,8))

level = np.arange(-4, 6., .25)
levels = [ level,  np.linspace(-1, 1, 6), level, level ] 


for i in range(4):
    
    ax = plt.axes( [ [.1, .6, .1, .6 ][i] , 
                    [.6,.6,.1,.1][i], 
                    .4, .4 ], projection = ccrs.PlateCarree())
    
    z = zz[i]
    print(z.max())

    cm1 = 'viridis'
    cmap = [ plt.colormaps[ cm ] for cm in [cm1, 'bwr', cm1, cm1] ][i]
    
    norm = mpl.colors.BoundaryNorm(levels[i], cmap.N)  
    t = ax.pcolormesh(lat2d, lon2d, z, cmap=cmap, norm=norm)

    #cax = fig.add_axes([0.92, 0.3, 0.02, 0.4])
    #cbar = plt.colorbar(orientation="vertical", ticks=lvl[1::2])
    #cbar.ax.tick_params(labelsize=12)


    fig.colorbar(t, orientation='horizontal')

    ax.text( .0, 1.02, 
            ['Low resolution', 'Error (High-res  prediction minus high-res real)', 'High resolution (prediction)', 'High resolution (real)' ][i], 
            fontsize = 15, 
            fontweight = 'bold',
            transform = ax.transAxes)



